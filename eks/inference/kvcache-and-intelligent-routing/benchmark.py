#!/usr/bin/env python3
"""
SageMaker HyperPod Inference KV Cache & Intelligent Routing ë²¤ì¹˜ë§ˆí¬
- Total Latency, TTFT (P90, P95, P99), Throughput (TPS) ì¸¡ì •
- ë™ì‹œ ìš”ì²­ 20ê±´ (ë³‘ë ¬)
- ê°™ì€ prefix vs ë‹¤ë¥¸ prefix ë¹„êµ
- 4K í† í° ì»¨í…ìŠ¤íŠ¸
"""

import boto3
import json
import time
import numpy as np
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

# ì„¤ì •
ENDPOINT_NAME = "deepseek7b-endpoint"
REGION = "us-east-2"
MODEL_NAME = "/opt/ml/model"
CONCURRENT_REQUESTS = 20

runtime = boto3.client("sagemaker-runtime", region_name=REGION)

# 4K í† í° ì»¨í…ìŠ¤íŠ¸ (ì•½ 3000ì)
LONG_CONTEXT = """
# 2024 ê¸€ë¡œë²Œ AI ì‚°ì—… ì¢…í•© ë³´ê³ ì„œ

## 1. ì‹œì¥ ê°œìš”
ê¸€ë¡œë²Œ AI ì‹œì¥ì€ 2024ë…„ 5,000ì–µ ë‹¬ëŸ¬ ê·œëª¨ë¡œ ì„±ì¥í–ˆìœ¼ë©°, ì—°í‰ê·  35% ì„±ì¥ë¥ ì„ ê¸°ë¡í•˜ê³  ìˆìŠµë‹ˆë‹¤.

### 1.1 ì§€ì—­ë³„ ë¶„ì„
ë¶ë¯¸ëŠ” 45% ì ìœ ìœ¨ë¡œ ìµœëŒ€ ì‹œì¥ì…ë‹ˆë‹¤. ë¯¸êµ­ì€ OpenAI, Google, Microsoft, Amazon ë“± ë¹…í…Œí¬ ê¸°ì—…ì˜ ë³¸ê±°ì§€ë¡œ AI ì—°êµ¬ê°œë°œì„ ì£¼ë„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ë¦¬ì½˜ë°¸ë¦¬ ìŠ¤íƒ€íŠ¸ì—… ìƒíƒœê³„ë„ í™œë°œí•˜ë©°, 2024ë…„ ìƒë°˜ê¸° AI ìŠ¤íƒ€íŠ¸ì—… íˆ¬ìê°€ 250ì–µ ë‹¬ëŸ¬ë¥¼ ë„˜ì—ˆìŠµë‹ˆë‹¤.

ìœ ëŸ½ì€ 25% ì ìœ ìœ¨ì´ë©°, GDPR ê¸°ë°˜ ê°•ë ¥í•œ ê·œì œ í”„ë ˆì„ì›Œí¬ë¡œ ì±…ì„ ìˆëŠ” AI ê°œë°œì„ ì„ ë„í•©ë‹ˆë‹¤. EU AI Act ì‹œí–‰ìœ¼ë¡œ ìœ„í—˜ ê¸°ë°˜ AI ê·œì œê°€ ë³¸ê²©í™”ë˜ì—ˆìœ¼ë©°, ì´ëŠ” ê¸€ë¡œë²Œ AI ê±°ë²„ë„ŒìŠ¤ì˜ í‘œì¤€ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤.

ì•„ì‹œì•„íƒœí‰ì–‘ì€ 30% ì ìœ ìœ¨ë¡œ ê°€ì¥ ë¹ ë¥¸ ì„±ì¥ì„¸ì…ë‹ˆë‹¤. ì¤‘êµ­ì€ ìì²´ LLM ê°œë°œê³¼ AI ì¹© ì œì¡°ì— ì§‘ì¤‘í•˜ë©° ê¸°ìˆ  ìë¦½ì„ ì¶”êµ¬í•˜ê³ , í•œêµ­ì€ ì‚¼ì„±ê³¼ LG ì¤‘ì‹¬ìœ¼ë¡œ AI ë°˜ë„ì²´ì™€ ê°€ì „ì— AIë¥¼ í†µí•©í•˜ê³  ìˆìŠµë‹ˆë‹¤.

### 1.2 ì‚°ì—…ë³„ ì ìš©
ê¸ˆìœµì—ì„œëŠ” ì‚¬ê¸° íƒì§€, ì‹ ìš© í‰ê°€, ì•Œê³ ë¦¬ì¦˜ íŠ¸ë ˆì´ë”©, ê³ ê° ì„œë¹„ìŠ¤ ìë™í™”ì— AIë¥¼ í™œìš©í•©ë‹ˆë‹¤. JP Morgan, Goldman Sachs ë“± ì£¼ìš” ê¸ˆìœµê¸°ê´€ë“¤ì€ AI ì—°êµ¬íŒ€ì„ í™•ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

í—¬ìŠ¤ì¼€ì–´ì—ì„œëŠ” AI ê¸°ë°˜ ì§„ë‹¨ ë³´ì¡° ì‹œìŠ¤í…œì´ ì˜ë£Œ í˜„ì¥ì— ë³´ê¸‰ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ìƒ ì§„ë‹¨, ë³‘ë¦¬ ë¶„ì„, ì‹ ì•½ ê°œë°œ, í™˜ì ëª¨ë‹ˆí„°ë§ì—ì„œ AI ì •í™•ë„ê°€ ì¸ê°„ ì „ë¬¸ê°€ ìˆ˜ì¤€ì— ë„ë‹¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì œì¡°ì—…ì—ì„œëŠ” í’ˆì§ˆ ê´€ë¦¬, ì˜ˆì¸¡ ì •ë¹„, ê³µê¸‰ë§ ìµœì í™”, ë¡œë´‡ ìë™í™”ì— AIë¥¼ í™œìš©í•˜ë©° ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ë¥¼ êµ¬í˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ë¦¬í…Œì¼ì—ì„œëŠ” ê°œì¸í™” ì¶”ì²œ, ì¬ê³  ê´€ë¦¬, ìˆ˜ìš” ì˜ˆì¸¡, ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡ì— AIê°€ í•„ìˆ˜ì ì¸ ìš”ì†Œê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.

## 2. ê¸°ìˆ  íŠ¸ë Œë“œ

### 2.1 ìƒì„±í˜• AI
2024ë…„ì€ ìƒì„±í˜• AIê°€ ì‹¤ìš©í™” ë‹¨ê³„ë¡œ ì§„ì…í•œ í•´ì…ë‹ˆë‹¤. GPT-4, Claude 3, Gemini Ultra ë“± LLM ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìœ¼ë©°, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤, ì½”ë“œ ìƒì„±ì´ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤.

ê¸°ì—…ë“¤ì€ ë²”ìš© LLMì„ ìì‚¬ ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹í•˜ê±°ë‚˜ RAG ê¸°ë²•ì„ í™œìš©í•˜ì—¬ íŠ¹í™”ëœ AI ì†”ë£¨ì…˜ì„ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤.

### 2.2 ë©€í‹°ëª¨ë‹¬ AI
í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ë¥¼ í†µí•© ì²˜ë¦¬í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ AIê°€ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. GPT-4V, GeminiëŠ” ì´ë¯¸ì§€ë¥¼ ì´í•´í•˜ê³  ì„¤ëª…í•  ìˆ˜ ìˆìœ¼ë©°, ì‹¤ì‹œê°„ ë²ˆì—­, ì½˜í…ì¸  ìƒì„±, ì˜ë£Œ ì§„ë‹¨ì—ì„œ í˜ì‹ ì  ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

### 2.3 ì—£ì§€ AI
í´ë¼ìš°ë“œ ì˜ì¡´ë„ë¥¼ ë‚®ì¶”ê³  ì‹¤ì‹œê°„ ì²˜ë¦¬ì™€ í”„ë¼ì´ë²„ì‹œë¥¼ ê°•í™”í•˜ê¸° ìœ„í•´ ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ AI ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ì¶”ì„¸ê°€ í™•ì‚°ë˜ê³  ìˆìŠµë‹ˆë‹¤.

## 3. ì£¼ìš” ê¸°ì—…

### 3.1 ë¹…í…Œí¬
OpenAIëŠ” GPT-4 Turboë¥¼ ì¶œì‹œí•˜ê³  ChatGPT Enterpriseë¥¼ í™•ëŒ€í•˜ë©° ê¸°ì—… ì‹œì¥ì„ ê³µëµí•˜ê³  ìˆìŠµë‹ˆë‹¤. Microsoftì™€ì˜ íŒŒíŠ¸ë„ˆì‹­ìœ¼ë¡œ Azure AIì— ê¹Šì´ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.

Googleì€ Gemini ëª¨ë¸ íŒ¨ë°€ë¦¬ë¥¼ ë°œí‘œí•˜ë©° ë©€í‹°ëª¨ë‹¬ AI ê²½ìŸì—ì„œ ìš°ìœ„ë¥¼ ì í•˜ë ¤ í•˜ê³  ìˆìŠµë‹ˆë‹¤. Workspace ì „ ì œí’ˆì— AIë¥¼ í†µí•©í•˜ê³  ìˆìŠµë‹ˆë‹¤.

MicrosoftëŠ” Copilotì„ Windows, Office, GitHub ë“± ëª¨ë“  ì œí’ˆêµ°ì— í™•ëŒ€í•˜ë©° AI-first ì „ëµì„ ì¶”ì§„í•˜ê³  ìˆìŠµë‹ˆë‹¤.

Amazonì€ Bedrock ì„œë¹„ìŠ¤ë¡œ ë‹¤ì–‘í•œ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ì„ ì œê³µí•˜ê³ , Q ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì¶œì‹œí•˜ì—¬ AWS ì‚¬ìš©ì ìƒì‚°ì„±ì„ ë†’ì´ê³  ìˆìŠµë‹ˆë‹¤.

MetaëŠ” LLaMA 3ë¥¼ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ê³µê°œí•˜ë©° AI ë¯¼ì£¼í™”ì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

### 3.2 ìŠ¤íƒ€íŠ¸ì—…
AI ìŠ¤íƒ€íŠ¸ì—… íˆ¬ìê°€ í­ë°œì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. 2024ë…„ ìƒë°˜ê¸° 250ì–µ ë‹¬ëŸ¬ê°€ íˆ¬ìë˜ì—ˆìœ¼ë©°, ì£¼ìš” ë¶„ì•¼ëŠ” AI ì—ì´ì „íŠ¸, ìˆ˜ì§ íŠ¹í™” LLM, AI ì¸í”„ë¼, AI ë³´ì•ˆì…ë‹ˆë‹¤.

## 4. ê·œì œ ë° ìœ¤ë¦¬

### 4.1 ê·œì œ
EU AI Actê°€ 2024ë…„ ë³¸ê²© ì‹œí–‰ë˜ë©° ìœ„í—˜ ê¸°ë°˜ AI ê·œì œì˜ ê¸€ë¡œë²Œ í‘œì¤€ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë¯¸êµ­ì€ ì£¼ ì •ë¶€ ì°¨ì›ì—ì„œ AI ê·œì œ ë²•ì•ˆì´ ë°œì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.

ì¤‘êµ­ì€ ìƒì„±í˜• AI ì„œë¹„ìŠ¤ ê·œì œë¥¼ ê°•í™”í•˜ë©° ì½˜í…ì¸  ê²€ì—´ê³¼ ë°ì´í„° ë³´ì•ˆì„ ì¤‘ì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì€ AI ê¸°ë³¸ë²• ì œì •ì„ ì¶”ì§„í•˜ê³  ìˆìŠµë‹ˆë‹¤.

### 4.2 ìœ¤ë¦¬
AIì˜ í¸í–¥ì„±ê³¼ ê³µì •ì„± ë¬¸ì œê°€ ì§€ì†ì ìœ¼ë¡œ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤. í•™ìŠµ ë°ì´í„°ì˜ í¸í–¥ì´ AI ê²°ì •ì— ì˜í–¥ì„ ë¯¸ì¹˜ë©°, ì±„ìš©, ëŒ€ì¶œ, í˜•ì‚¬ì‚¬ë²•ì—ì„œ ì°¨ë³„ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## 5. ë¯¸ë˜ ì „ë§

### 5.1 ë‹¨ê¸° (2025-2026)
AGI ì—°êµ¬ê°€ ê°€ì†í™”ë  ê²ƒì…ë‹ˆë‹¤. í˜„ì¬ LLMì„ ë„˜ì–´ ë” ë²”ìš©ì ì´ê³  ììœ¨ì ì¸ AI ì‹œìŠ¤í…œ ê°œë°œì´ ì§„í–‰ë  ê²ƒì…ë‹ˆë‹¤.

AI ì—ì´ì „íŠ¸ì˜ ì‹¤ìš©í™”ê°€ í™•ëŒ€ë˜ì–´ ë³µì¡í•œ ì—…ë¬´ë¥¼ ìë™í™”í•˜ê³  ì¸ê°„ê³¼ í˜‘ì—…í•˜ëŠ” ì‚¬ë¡€ê°€ ì¦ê°€í•  ê²ƒì…ë‹ˆë‹¤.
""" * 2  # ì•½ 4K í† í°

# ë‹¤ë¥¸ prefix ì»¨í…ìŠ¤íŠ¸ë“¤
DIFFERENT_CONTEXTS = [
    f"DOCUMENT_{i}: " + "ì™„ì „íˆ ë‹¤ë¥¸ ë‚´ìš©ì…ë‹ˆë‹¤. " * 400 for i in range(20)
]

def invoke_with_streaming(payload, session_id):
    """ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ TTFT ì¸¡ì •"""
    payload_with_session = {**payload, "user_id": session_id, "stream": True}
    
    start_time = time.time()
    ttft = None
    
    try:
        response = runtime.invoke_endpoint_with_response_stream(
            EndpointName=ENDPOINT_NAME,
            ContentType="application/json",
            Body=json.dumps(payload_with_session)
        )
        
        event_stream = response['Body']
        for event in event_stream:
            if 'PayloadPart' in event:
                if ttft is None:
                    ttft = time.time() - start_time
                break
        
        # ìŠ¤íŠ¸ë¦¼ ì™„ì „íˆ ì†Œë¹„í•˜ê³  ë‹«ê¸°
        try:
            for _ in event_stream:
                pass
        except:
            pass
        
        return ttft
    except Exception as e:
        return None

def invoke_endpoint(payload, session_id):
    """ì¼ë°˜ í˜¸ì¶œë¡œ ì „ì²´ ì§€ì—°ì‹œê°„ ì¸¡ì •"""
    payload_with_session = {**payload, "user_id": session_id}
    
    start_time = time.time()
    
    try:
        response = runtime.invoke_endpoint(
            EndpointName=ENDPOINT_NAME,
            ContentType="application/json",
            Body=json.dumps(payload_with_session)
        )
        
        latency = time.time() - start_time
        result = json.loads(response["Body"].read().decode())
        
        return {
            'success': True,
            'latency': latency,
            'total_tokens': result['usage']['total_tokens'],
            'completion_tokens': result['usage']['completion_tokens']
        }
    except Exception as e:
        return {'success': False, 'error': str(e)}

def single_request(request_id, context, session_id):
    """ë‹¨ì¼ ìš”ì²­ ì‹¤í–‰"""
    payload = {
        "model": MODEL_NAME,
        "messages": [{"role": "user", "content": f"{context}\n\nì§ˆë¬¸: ìš”ì•½í•´ì£¼ì„¸ìš”."}],
        "max_tokens": 100,
        "temperature": 0.7
    }
    
    # TTFT ì¸¡ì •
    ttft = invoke_with_streaming(payload, session_id)
    
    # ì „ì²´ ì§€ì—°ì‹œê°„ ì¸¡ì •
    result = invoke_endpoint(payload, session_id)
    
    if result['success']:
        return {
            'request_id': request_id,
            'session_id': session_id,
            'ttft': ttft,
            'latency': result['latency'],
            'tokens': result['total_tokens'],
            'completion_tokens': result['completion_tokens']
        }
    return None

def run_concurrent_test(context_type, use_same_context=True):
    """ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸"""
    print(f"\n{'='*80}")
    print(f"ğŸ¯ í…ŒìŠ¤íŠ¸: {context_type}")
    print(f"{'='*80}")
    
    results = []
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=CONCURRENT_REQUESTS) as executor:
        futures = []
        
        for i in range(CONCURRENT_REQUESTS):
            context = LONG_CONTEXT if use_same_context else DIFFERENT_CONTEXTS[i]
            session_id = f"session_{i+1}"
            
            future = executor.submit(single_request, i+1, context, session_id)
            futures.append(future)
        
        for future in as_completed(futures):
            result = future.result()
            if result:
                results.append(result)
                print(f"  âœ“ ìš”ì²­ {result['request_id']:2d} | Session: {result['session_id']:12s} | "
                      f"TTFT: {result['ttft']:.2f}s | Latency: {result['latency']:.2f}s")
    
    total_duration = time.time() - start_time
    
    return results, total_duration

def analyze_results(same_results, diff_results, same_duration, diff_duration):
    """ê²°ê³¼ ë¶„ì„"""
    print(f"\n{'='*80}")
    print("ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼")
    print(f"{'='*80}\n")
    
    # TTFT ë¶„ì„
    same_ttft = [r['ttft'] for r in same_results if r['ttft']]
    diff_ttft = [r['ttft'] for r in diff_results if r['ttft']]
    
    print("â±ï¸  TTFT (Time To First Token)")
    print("-" * 80)
    print(f"{'Metric':<20} {'ê°™ì€ Prefix':>15} {'ë‹¤ë¥¸ Prefix':>15} {'ê°œì„ ìœ¨':>15}")
    print("-" * 80)
    
    for p in [50, 90, 95, 99]:
        same_p = np.percentile(same_ttft, p)
        diff_p = np.percentile(diff_ttft, p)
        improvement = ((diff_p - same_p) / diff_p * 100)
        print(f"P{p:<18} {same_p:>14.2f}s {diff_p:>14.2f}s {improvement:>14.1f}%")
    
    # Total Latency ë¶„ì„
    same_latency = [r['latency'] for r in same_results]
    diff_latency = [r['latency'] for r in diff_results]
    
    print(f"\nâ±ï¸  Total Latency")
    print("-" * 80)
    print(f"{'Metric':<20} {'ê°™ì€ Prefix':>15} {'ë‹¤ë¥¸ Prefix':>15} {'ê°œì„ ìœ¨':>15}")
    print("-" * 80)
    
    for p in [50, 90, 95, 99]:
        same_p = np.percentile(same_latency, p)
        diff_p = np.percentile(diff_latency, p)
        improvement = ((diff_p - same_p) / diff_p * 100)
        print(f"P{p:<18} {same_p:>14.2f}s {diff_p:>14.2f}s {improvement:>14.1f}%")
    
    # Throughput ë¶„ì„
    same_total_tokens = sum(r['tokens'] for r in same_results)
    diff_total_tokens = sum(r['tokens'] for r in diff_results)
    
    same_tps = same_total_tokens / same_duration
    diff_tps = diff_total_tokens / diff_duration
    
    print(f"\nğŸš€ Throughput (TPS)")
    print("-" * 80)
    print(f"{'Metric':<20} {'ê°™ì€ Prefix':>15} {'ë‹¤ë¥¸ Prefix':>15} {'ê°œì„ ìœ¨':>15}")
    print("-" * 80)
    print(f"{'TPS':<20} {same_tps:>14.1f} {diff_tps:>14.1f} {((same_tps - diff_tps) / diff_tps * 100):>14.1f}%")
    print(f"{'Total Tokens':<20} {same_total_tokens:>15} {diff_total_tokens:>15}")
    print(f"{'Duration':<20} {same_duration:>14.1f}s {diff_duration:>14.1f}s")
    
    # ìš”ì•½
    print(f"\n{'='*80}")
    print("ğŸ¯ í•µì‹¬ ìš”ì•½")
    print(f"{'='*80}")
    
    same_ttft_p90 = np.percentile(same_ttft, 90)
    diff_ttft_p90 = np.percentile(diff_ttft, 90)
    ttft_improvement = ((diff_ttft_p90 - same_ttft_p90) / diff_ttft_p90 * 100)
    
    same_lat_p90 = np.percentile(same_latency, 90)
    diff_lat_p90 = np.percentile(diff_latency, 90)
    lat_improvement = ((diff_lat_p90 - same_lat_p90) / diff_lat_p90 * 100)
    
    tps_improvement = ((same_tps - diff_tps) / diff_tps * 100)
    
    print(f"âœ… TTFT P90 ê°œì„ : {ttft_improvement:.1f}%")
    print(f"âœ… Latency P90 ê°œì„ : {lat_improvement:.1f}%")
    print(f"âœ… Throughput í–¥ìƒ: {tps_improvement:.1f}%")
    print(f"\nğŸ’¡ Intelligent Routing & KV Cacheê°€ ê°™ì€ prefix ìš”ì²­ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬!")

if __name__ == "__main__":
    print("ğŸš€ SageMaker HyperPod Inference ë²¤ì¹˜ë§ˆí¬")
    print(f"ë™ì‹œ ìš”ì²­: {CONCURRENT_REQUESTS}ê±´")
    print(f"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: ì•½ 4K í† í°\n")
    
    # í…ŒìŠ¤íŠ¸ 1: ê°™ì€ prefix
    same_results, same_duration = run_concurrent_test(
        "ê°™ì€ Prefix ë™ì‹œ ìš”ì²­", use_same_context=True
    )
    
    time.sleep(2)
    
    # í…ŒìŠ¤íŠ¸ 2: ë‹¤ë¥¸ prefix
    diff_results, diff_duration = run_concurrent_test(
        "ë‹¤ë¥¸ Prefix ë™ì‹œ ìš”ì²­", use_same_context=False
    )
    
    # ê²°ê³¼ ë¶„ì„
    analyze_results(same_results, diff_results, same_duration, diff_duration)
    
    print(f"\n{'='*80}")
    print("âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    print(f"{'='*80}")
